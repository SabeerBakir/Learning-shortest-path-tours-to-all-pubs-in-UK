{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models\n",
    "\n",
    "This notebook will create Machine Learning models and test their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import joblib\n",
    "\n",
    "import model_utils as M\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and split into Training and Testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../6_feature_engineering/Feature_Dataset/'\n",
    "data_files = [i for i in os.listdir(DATA_DIR) if i.endswith('.csv')]\n",
    "data_files.sort()\n",
    "df_TSP_list = [pd.read_csv(DATA_DIR + file) for file in data_files]\n",
    "\n",
    "for i in range(len(df_TSP_list)):\n",
    "    # Convert booleans to int\n",
    "    df_TSP_list[i] = df_TSP_list[i].astype({'IS_IN_1ST_QUARTILE': 'int64',\n",
    "                                            'IS_IN_2ND_QUARTILE': 'int64',\n",
    "                                            'IS_IN_3RD_QUARTILE': 'int64',\n",
    "                                            'EDGE_IN_SOL': 'int64'})\n",
    "    df_TSP_list[i] = df_TSP_list[i].reset_index(drop=True)\n",
    "    \n",
    "df_TSP_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1` is True and `0` is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df_TSP_list[:5]\n",
    "test_set = df_TSP_list[5:]\n",
    "\n",
    "print(\"Train Data Graphs:\\t{}\".format(len(train_set)))\n",
    "print(\"Test Data Graphs:\\t{}\".format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat(train_set).reset_index(drop=True)\n",
    "df_test = pd.concat(test_set).reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.pop('EDGE_IN_SOL').values\n",
    "y_test = df_test.pop('EDGE_IN_SOL').values\n",
    "X_train = df_train.values\n",
    "X_test = df_test.values\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into 50% for training and 50% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "TSP_NB = gnb.fit(X_train, y_train)\n",
    "y_dash_NB = TSP_NB.predict(X_test)\n",
    "joblib.dump(TSP_NB, 'Models/TSP_NB_model.pkl') # Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Confusion Matrix\n",
    "With the confusion matrix, rows are actual and columns are predicted.   \n",
    "If 0 is negative and 1 is positive `C(0,0)` is TN and `C(1,1)` is TP.  \n",
    "TN, FP  \n",
    "FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_dash_NB)\n",
    "print(\"Accuracy: {0:.2f}\".format(acc)) \n",
    "confusion = confusion_matrix(y_test, y_dash_NB)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion)) \n",
    "f1 = f1_score(y_test, y_dash_NB)\n",
    "print(\"F1 score: {0:.2f}\".format(f1))\n",
    "precision = precision_score(y_test, y_dash_NB)\n",
    "print(\"Precision score: {0:.2f}\".format(precision))\n",
    "recall = recall_score(y_test, y_dash_NB)\n",
    "print(\"Recall score: {0:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSP_LR = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "TSP_LR.fit(X_train, y_train)\n",
    "y_dash_LR = TSP_LR.predict(X_test)\n",
    "joblib.dump(TSP_LR, 'Models/TSP_LR_model.pkl') # Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_dash_LR)\n",
    "print(\"Accuracy: {0:.2f}\".format(acc)) \n",
    "confusion = confusion_matrix(y_test, y_dash_LR)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion)) \n",
    "f1 = f1_score(y_test, y_dash_LR)\n",
    "print(\"F1 score: {0:.2f}\".format(f1))\n",
    "precision = precision_score(y_test, y_dash_LR)\n",
    "print(\"Precision score: {0:.2f}\".format(precision))\n",
    "recall = recall_score(y_test, y_dash_LR)\n",
    "print(\"Recall score: {0:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Look at current parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSP_RF = RandomForestClassifier(random_state=0)\n",
    "TSP_RF.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator=TSP_RF, param_distributions=random_grid, n_iter=100, cv=2, verbose=2, random_state=42, n_jobs=-1, scoring='f1')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters found by Randomized Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Save Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSP_RF = RandomForestClassifier(**rf_random.best_params_)\n",
    "TSP_RF.fit(X_train, y_train)\n",
    "joblib.dump(TSP_RF, 'Models/TSP_RF_model.pkl') # Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSP_RF = joblib.load('Models/TSP_RF_model.pkl')\n",
    "TSP_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local grid search around the parameters found by randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {'n_estimators': [rf_random.best_params_['n_estimators']-100,rf_random.best_params_['n_estimators'],rf_random.best_params_['n_estimators']+100],\n",
    "              'min_samples_split': [rf_random.best_params_['min_samples_split']-1, rf_random.best_params_['min_samples_split'], rf_random.best_params_['min_samples_split']+1],\n",
    "              'min_samples_leaf': [rf_random.best_params_['min_samples_leaf']-1, rf_random.best_params_['min_samples_leaf'], rf_random.best_params_['min_samples_leaf']+1],\n",
    "              'max_features': [rf_random.best_params_['max_features']],\n",
    "              'max_depth': [rf_random.best_params_['max_depth']-1, rf_random.best_params_['max_depth'], rf_random.best_params_['max_depth']+1],\n",
    "              'bootstrap': [rf_random.best_params_['bootstrap']]\n",
    "             }\n",
    "\n",
    "\n",
    "# Create a base model\n",
    "TSP_RF = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=TSP_RF, param_grid=param_grid, \n",
    "                          cv=2, n_jobs=-1, verbose=2, return_train_score=True, scoring='f1')\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and save final Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSP_RF = RandomForestClassifier(**grid_search.best_params_)\n",
    "TSP_RF.fit(X_train, y_train)\n",
    "joblib.dump(TSP_RF, 'Models/TSP_RF_model.pkl') # Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_df = pd.DataFrame(TSP_RF.feature_importances_, index=df_TSP_list[0].columns[:-1], columns =['Feature Importance Score'])\n",
    "FI_df.sort_values('Feature Importance Score', inplace=True, ascending=False)\n",
    "FI_df['Feature Importance Score'] = FI_df['Feature Importance Score'].apply(lambda x: np.around(x, 7))\n",
    "FI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dash_RF = TSP_RF.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_dash_RF)\n",
    "print(\"Accuracy: {0:.2f}\".format(acc)) \n",
    "confusion = confusion_matrix(y_test, y_dash_RF)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion)) \n",
    "f1 = f1_score(y_test, y_dash_RF)\n",
    "print(\"F1 score: {0:.2f}\".format(f1))\n",
    "precision = precision_score(y_test, y_dash_RF)\n",
    "print(\"Precision score: {0:.2f}\".format(precision))\n",
    "recall = recall_score(y_test, y_dash_RF)\n",
    "print(\"Recall score: {0:.2f}\".format(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
