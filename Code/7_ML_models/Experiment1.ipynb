{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Ground Truth Edges vs. Threshold\n",
    "\n",
    "This notebook will look at how the threshold value effects the prune ratio and the amount of ground truth edges in the tour predicted by a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import joblib\n",
    "import model_utils as M\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSP_NB = joblib.load('Models/TSP_NB_model.pkl')\n",
    "TSP_LR = joblib.load('Models/TSP_LR_model.pkl')\n",
    "TSP_RF = joblib.load('Models/TSP_RF_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../6_feature_engineering/Feature_Dataset/'\n",
    "data_files = [i for i in os.listdir(DATA_DIR) if i.endswith('.csv')]\n",
    "data_files.sort()\n",
    "df_TSP_list = [pd.read_csv(DATA_DIR + file) for file in data_files]\n",
    "\n",
    "for i in range(len(df_TSP_list)):\n",
    "    # Convert booleans to int\n",
    "    df_TSP_list[i] = df_TSP_list[i].astype({'IS_IN_1ST_QUARTILE': 'int64',\n",
    "                                            'IS_IN_2ND_QUARTILE': 'int64',\n",
    "                                            'IS_IN_3RD_QUARTILE': 'int64',\n",
    "                                            'EDGE_IN_SOL': 'int64'})\n",
    "    df_TSP_list[i] = df_TSP_list[i].reset_index(drop=True)\n",
    "    \n",
    "train_set = df_TSP_list[:5]\n",
    "test_set = df_TSP_list[5:]\n",
    "\n",
    "test_set[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the coordinates for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COORD_DATA_DIR = '../5_ground_truth/Final_Dataset/'\n",
    "coord_datafiles = [i for i in os.listdir(COORD_DATA_DIR) if i.endswith('.csv')]\n",
    "coord_datafiles.sort()\n",
    "\n",
    "df_coord_list = [pd.read_csv(COORD_DATA_DIR + file) for file in coord_datafiles]\n",
    "\n",
    "for i in range(len(df_coord_list)):\n",
    "    df_coord_list[i]['NODE1_COORDS'] = df_coord_list[i]['NODE1_COORDS'].apply(eval)\n",
    "    df_coord_list[i]['NODE2_COORDS'] = df_coord_list[i]['NODE2_COORDS'].apply(eval)\n",
    "\n",
    "train_coords = df_coord_list[:5]\n",
    "test_coords = df_coord_list[5:]\n",
    "\n",
    "test_coords[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_num = 0 # For changing between different test graphs\n",
    "cols = test_set[set_num].columns[:-1]  # Every column except the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes Threshold Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_precisions = np.array([])\n",
    "NB_ground_truth_count = np.array([])\n",
    "\n",
    "\n",
    "X = test_set[set_num][cols].values\n",
    "\n",
    "step = 0.05\n",
    "for t in np.arange(0, 1+step, step):\n",
    "    tour = M.threshold_tour(X, test_coords[set_num], TSP_NB, threshold=t)\n",
    "    NB_precisions = np.append(NB_precisions, M.precision(tour))\n",
    "    NB_ground_truth_count = np.append(NB_ground_truth_count, M.ground_truth_count(tour))\n",
    "\n",
    "print(\"Naïve Bayes\")\n",
    "print(\"Average Precision: {}\".format(NB_precisions))\n",
    "print(\"Average Ground Truth Count: {}\".format(NB_ground_truth_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Threshold\": np.arange(0, 1+step, step),\n",
    "                   \"NB precisions\": NB_precisions, \n",
    "                   \"NB ground truth count\": NB_ground_truth_count})\n",
    "\n",
    "ax = df.plot(x=\"Threshold\", y=\"NB precisions\", legend=False, figsize=(10,5))\n",
    "ax2 = ax.twinx()\n",
    "df.plot(x=\"Threshold\", y=\"NB ground truth count\", ax=ax2, legend=False, color=\"r\")\n",
    "ax.figure.legend(loc=(0.77,0.91))\n",
    "\n",
    "plt.title(\"Naïve Bayes: Threshold vs. Precision and Ground Truth Count (Graph {})\".format(set_num))\n",
    "ax.set_ylabel('Precision')\n",
    "ax2.set_ylabel('Ground Truth Count')\n",
    "\n",
    "plt.savefig('exp1/NB thresh vs. precision and gtruth {}.pdf'.format(set_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Threshold Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_precisions = np.array([])\n",
    "LR_ground_truth_count = np.array([])\n",
    "\n",
    "\n",
    "X = test_set[set_num][cols].values\n",
    "\n",
    "step = 0.05\n",
    "for t in np.arange(0, 1+step, step):\n",
    "    tour = M.threshold_tour(X, test_coords[set_num], TSP_LR, threshold=t)\n",
    "    LR_precisions = np.append(LR_precisions, M.precision(tour))\n",
    "    LR_ground_truth_count = np.append(LR_ground_truth_count, M.ground_truth_count(tour))\n",
    "    \n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Precision: {}\".format(LR_precisions))\n",
    "print(\"Ground Truth Count: {}\".format(LR_ground_truth_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Threshold\": np.arange(0, 1+step, step),\n",
    "                   \"LR precisions\": LR_precisions, \n",
    "                   \"LR ground truth count\": LR_ground_truth_count})\n",
    "\n",
    "ax = df.plot(x=\"Threshold\", y=\"LR precisions\", legend=False, figsize=(10,5))\n",
    "ax2 = ax.twinx()\n",
    "df.plot(x=\"Threshold\", y=\"LR ground truth count\", ax=ax2, legend=False, color=\"r\")\n",
    "ax.figure.legend(loc=(0.77,0.91))\n",
    "\n",
    "plt.title(\"Logistic Regression: Threshold vs. Precision and Ground Truth Count (Graph {})\".format(set_num))\n",
    "ax.set_ylabel('Precision')\n",
    "ax2.set_ylabel('Ground Truth Count')\n",
    "\n",
    "plt.savefig('exp1/LR thresh vs. precision and gtruth {}.pdf'.format(set_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Threshold Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_precisions = np.array([])\n",
    "RF_ground_truth_count = np.array([])\n",
    "\n",
    "\n",
    "X = test_set[set_num][cols].values\n",
    "\n",
    "step = 0.05\n",
    "for t in np.arange(0, 1+step, step):\n",
    "    tour = M.threshold_tour(X, test_coords[set_num], TSP_RF, threshold=t)\n",
    "    RF_precisions = np.append(RF_precisions, M.precision(tour))\n",
    "    RF_ground_truth_count = np.append(RF_ground_truth_count, M.ground_truth_count(tour))\n",
    "\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"Precision: {}\".format(RF_precisions))\n",
    "print(\"Ground Truth Count: {}\".format(RF_ground_truth_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Threshold\": np.arange(0, 1+step, step),\n",
    "                   \"RF precisions\": RF_precisions, \n",
    "                   \"RF ground truth count\": RF_ground_truth_count})\n",
    "\n",
    "ax = df.plot(x=\"Threshold\", y=\"RF precisions\", legend=False, figsize=(10,5))\n",
    "ax2 = ax.twinx()\n",
    "df.plot(x=\"Threshold\", y=\"RF ground truth count\", ax=ax2, legend=False, color=\"r\")\n",
    "ax.figure.legend(loc=(0.77,0.91))\n",
    "\n",
    "plt.title(\"Random Forest: Threshold vs. Precision and Ground Truth Count (Graph {})\".format(set_num))\n",
    "ax.set_ylabel('Precision')\n",
    "ax2.set_ylabel('Ground Truth Count')\n",
    "\n",
    "plt.savefig('exp1/RF thresh vs. precision and gtruth {}.pdf'.format(set_num))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
